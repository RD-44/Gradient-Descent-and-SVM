{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Important - do this first!\n",
    "\n",
    "**Double click here and enter the student numbers for all group members. Do not enter any names.**\n",
    "\n",
    "1. (student number)\n",
    "2. (student number)\n",
    "3. (student number)\n",
    "4. (student number)\n",
    "\n",
    "Now **[click on this link and read the MATH0011 project instructions.](https://www.ucl.ac.uk/~ucahmto/0011/project-instructions.html)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In this project you will implement your own version of one of the most fundamental optimization algorithms, [gradient descent](https://en.wikipedia.org/wiki/Gradient_descent), test it out on some example functions, and create a visualisation of the result.  After that you'll use one of the optimizers built in to the [`scipy`](https://scipy.org/) module to implement a commonly-used machine learning model called the support vector machine, and again visualise the results on some simulated data.\n",
    "\n",
    "The project is a good fit for people interested in artificial intelligence/machine learning. There is some flexibility in how to store the data you are generating and working with, so you will also gain experience of choosing appropriate representations (and probably learn why certain bad choices are not so good).  Don't be afraid to go back and change the code you have already written if you begin to regret the decisions you made earlier.  There is quite a bit of code to write, but you will certainly learn some useful things.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Part 1 - gradient descent and ascent\n",
    "\n",
    "Gradient ascent and descent are algorithms for finding [local minimums and maximums](https://www.mathsisfun.com/algebra/functions-maxima-minima.html) of a differentiable function of several variables.  In this part you will implement a simple version of gradient descent for functions $F : \\mathbb{R}^2 \\to \\mathbb{R}$ and learn how to create plots that demonstrate the behaviour of the algorithm using `matplotlib` and NumPy.\n",
    "\n",
    "First we need some definitions. The **gradient** of a function $F : \\mathbb{R}^2 \\to \\mathbb{R}$, written $\\nabla F$, is the function $\\nabla F : \\mathbb{R}^2 \\to \\mathbb{R}^2$ given by \n",
    "\n",
    "$$ \\nabla F (\\mathbf{v}) = \\begin{pmatrix} \\frac{\\partial F}{\\partial x} (\\mathbf{v}) \\\\ \\frac{\\partial F}{\\partial y}(\\mathbf{v})\\end{pmatrix} $$\n",
    "\n",
    "where $\\frac{\\partial F}{\\partial x} (\\mathbf{v})$ is the [partial derivative](https://en.wikipedia.org/wiki/Partial_derivative) defined by\n",
    "\n",
    "$$ \\frac{\\partial F}{\\partial x} (v_1, v_2) = \\lim_{h\\to 0} \\frac{F(v_1+h, v_2) - F(v_1, v_2)}{h} $$ \n",
    "\n",
    "and $\\frac{\\partial F}{\\partial y}$ is defined similarly.\n",
    "\n",
    "For example, if $F(x, y) = xy + x^2 + 2y + 3$ then \n",
    "\n",
    "$$\\frac{\\partial F}{\\partial x} (x, y) = y + 2x \\;\\;\\;\\; \\frac{\\partial F}{\\partial y}(x,y) = x + 2$$\n",
    "\n",
    "so $\\nabla F (x, y) = \\begin{pmatrix} y+2x \\\\ x+2 \\end{pmatrix}$.\n",
    "\n",
    "The significance of the gradient is that at a point $\\mathbf{v} \\in \\mathbb{R}^2$, the direction in which $F$ increases fastest is $\\nabla F( \\mathbf{v})$ and the direction in which $F$ decreases fastest is $-\\nabla F(\\mathbf{v})$.  You'll learn more about this after reading week in MATH0011.\n",
    "\n",
    "The gradient gives us a simple way of looking for a local maximum of a function $F: \\mathbb{R}^2 \\to \\mathbb{R}$. Pick some point $\\mathbf{a}_0$ to start off at, then move a small distance in the direction of $\\nabla F( \\mathbf{a}_0)$, taking you to a new point $\\mathbf{a}_1$ with a bigger value of $F$, then move a small distance in the direction of $\\nabla F(\\mathbf{a}_1)$ to a new point $\\mathbf{a}_2$, and so on.  This is gradient ascent.  (To see how the method works, imagine you are standing somewhere on a foggy mountain and want to climb to the top.  If you keep walking in the steepest uphill direction you can find, you may eventually get to the top, as long as there is only one peak).  To find a local minimum value of $F$ we can do the same thing except we move in the direction $- \\nabla F$, since this is the direction in which $F$ decreases fastest - this is gradient *de*scent.\n",
    "\n",
    "**Write a function `approx_grad(f, v, h)` which returns an approximation to the gradient of the function `f` at the point `v` using a change in x and y of `h`.**\n",
    "\n",
    "`f` will be a function of two variables and `v` will be a list `[a, b]` or a NumPy array giving the coordinates of the point at which you will approximate the gradient of `f`.\n",
    "\n",
    "**Your function must return a tuple of length 2** (or a NumPy array, if it makes your code easier to use) whose first element is\n",
    "\n",
    "$$\\frac{f(a+h, b) - f(a, b)}{h} $$\n",
    "\n",
    "which is an approximation of $\\frac{\\partial f}{\\partial x}(a, b)$, and whose second element is\n",
    "\n",
    "$$\\frac{f(a, b+h) - f(a, b)}{h} $$\n",
    "\n",
    "which is an approximation of $\\frac{\\partial f}{\\partial y}(a, b)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def approx_grad(f, v, h):\n",
    "    a = v[0]\n",
    "    b = v[1]\n",
    "    dx = (f(a+h,b) - f(a,b))/h\n",
    "    dy = (f(a,b+h) - f(a,b))/h\n",
    "    return (dx, dy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Check your approximation** for the function $F(x, y) = xy + x^2 + 2y + 3$ by comparing it to the partial derivatives given above.  Try values of `x` and `y` between `-3` and `3` and experiment to see how `h` affects how close the approximation is to the true value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'NoneType' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_227/926689101.py\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mapprox_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_227/298287187.py\u001b[0m in \u001b[0;36mapprox_grad\u001b[0;34m(f, v, h)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mdy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'NoneType' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "def f(x, y):\n",
    "    x*y + x**2 + 2*y + 3\n",
    "    \n",
    "approx_grad(lambda x, y : f(x,y) , [-3, 3], 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The gradient descent algorithm for a function $f : \\mathbb{R}^2 \\to \\mathbb{R}$ that you are going to implement begins with a point $\\mathbf{a}_0 \\in \\mathbb{R}^2$ and produces a sequence defined by\n",
    "\n",
    "$$ \\mathbf{a}_{i+1} \\approx \\mathbf{a}_i - k \\nabla f (\\mathbf{a}_i) $$\n",
    "\n",
    "where $k$ is a fixed small positive number called the *step size*. The reason I have written $\\approx$ and not $=$ is that you are going to use your `approx_grad` function to obtain an approximation to $\\nabla f(\\mathbf{a}_i)$ in place of the actual gradient.\n",
    "\n",
    "**Write a function `gradient_descent_sequence(f, a0, k, h, N)`** which behaves as follows.\n",
    "\n",
    " - `f` is a function of two variables\n",
    " - `a0` is a list of length 2 containing the x and y coordinates of the starting point of the gradient descent algorithm\n",
    " - `k` is the step size, as above\n",
    " - `h` is the change in x and y used to calculate an approximation to the gradient, which you will pass to your function from part 1\n",
    " - `N` specifies the number of terms of the gradient descent sequence after `a0` to be calculated\n",
    " \n",
    "**The output of your function should be a tuple of two lists of numbers**, the first list being the x-coordinates of the sequence $\\mathbf{a}_0, \\mathbf{a}_1, \\ldots, \\mathbf{a}_{N}$ and the second list being the y-coordinates.  Again, you can use arrays instead of tuples and lists if you prefer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def gradient_descent_sequence(f, a0, k, h, N):\n",
    "    # your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Part 2 - plotting the gradient descent sequences\n",
    "\n",
    "**Calculate the gradient descent sequence** for the function $g(x, y) = x^2 + 2y^2$ starting at $(1, -1)$ with `N = 10`, `k = 0.2`, `h = 0.1`, then **plot the points in the gradient descent sequence** using the `matplotlib.pyplot` function `plot` .  The function has its minimum at $(0, 0)$, so you should see the line tending towards the origin.\n",
    "\n",
    "To make your plot look better, you may want to experiment with the `linewidth` parameter to the `plot` command\n",
    "\n",
    "```python\n",
    "plt.plot(xs, ys, 'r-', linewidth=0.5)\n",
    "```\n",
    "and to use `plt.xlim()` and `plt.ylim()` to control the range of x-coordinates and y-coordinates which are plotted. [This link](https://stackabuse.com/how-to-set-axis-range-xlim-ylim-in-matplotlib/) has some examples on the use of `xlim` and `ylim`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# plotting code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The plot above isn't very satisfying.  It would be better if you could see both the points of the gradient descent sequence and a visual representation of the function whose minimum you are looking for on the same axes, so that you can see what the gradient ascent/descent algorithm is doing.   Since you are working with functions $f : \\mathbb{R}^2 \\to \\mathbb{R}$ you need to indicate the value of $f$ at the point $(x, y)$ in some way.  In this part you will use `matplotlib`'s functions `contour` and `contourf` to make a plot that uses colours and contours to indicate the value of a function $f$ at the point $(x, y) \\in \\mathbb{R}^2$.\n",
    "\n",
    "Start by reading [the Wikipedia article on contour lines](https://en.wikipedia.org/wiki/Contour_line) until you understand what a contour plot is.\n",
    "\n",
    "The `contour` function from `matplotlib.pyplot` is used in a similar way to the `plot` command, except that you must supply lists or numpy arrays of the x-coordinates, y-coordinates, and z-coordinates for your plot.  Luckily NumPy has functions which make this a lot easier.  We will keep things by simple by choosing x-coordinates and y-coordinates on a rectangular grid - for example, if the x-values are 1, 2, 3 and the y-values are 4, 5, 6 then the grid points would be at (1, 4), (1, 5), (1, 6), (2, 4), (2, 5), (2, 6), (3, 4), (3, 5), (3, 6).\n",
    "\n",
    "First, produce arrays of the x-values and y-values using `np.linspace`:\n",
    "\n",
    "```python\n",
    "x_grid_values = np.linspace(-5, 5, 100)\n",
    "y_grid_values = np.linspace(-5, 5, 100)\n",
    "```\n",
    "\n",
    "The numpy function `meshgrid` will assemble these into arrays containing all of the x- and y-coordinates we need for the plot.\n",
    "\n",
    "```python\n",
    "xs, ys = np.meshgrid(x_grid_values, y_grid_values)\n",
    "```\n",
    "\n",
    "Next, get the z-value for each of the gridpoints.  You could do this using some for loops, but again there is a numpy function to make it easy: if `g(x, y)` is a two-variable function which we want to apply to every one of our grid points, then `np.vectorize(g)` is a new function which can be applied to `xs` and `ys` to give the array of z-coordinates we need.\n",
    "\n",
    "```python\n",
    "zs = np.vectorize(g)(xs, ys)\n",
    "```\n",
    "\n",
    "Having prepared the x-, y-, and z-coordinates you can now just call `plt.contour(xs, ys, zs)` or `plt.contourf(xs, ys, zs)` to produce our contour plots.  You can experiment with `plt.contour(xs, ys, zs, levels=N)` where `N` is an integer to control how many contours are plotted.  Other ways to get the plot looking good are:\n",
    "\n",
    " - try `plt.axis('scaled')` to adjust scaling of the axes\n",
    " - calling `plt.colorbar()` shows how values of the function correspond to colours in the plot\n",
    " - read about colourmaps [here](https://matplotlib.org/stable/tutorials/colors/colormaps.html) and then try `plt.contour(xs, ys, zs, levels=N, cmap=plt.get_cmap('turbo'))` for example.\n",
    " \n",
    "**Following the instructions above, produce a `contour` or `contourf` plot of the function `g` defined below using values of `x` and `y` between -5 and 5.**  Include a colourbar in your plot, and experiment with parameter values to get the plot looking as good as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def g(x, y):\n",
    "    return ((x**2 + y -11)**2 + (x+y**2 - 6)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# make the contour plot of g here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Finally, **use `contourf` to plot the function `g` above** and on the same plot, **use `plot` to show the points generated by `gradientDescentSequence` starting at (0, -3)**, adjusting `h`, `k`, and `N` so that they converge to one of the local minimums.  Indicate the starting point (0, -3) on the plot somehow and choose plotting colours and a colour map so that it is easy to see what is happening in the plot.\n",
    "\n",
    "You should see the gradient descent sequence going into one of the dark coloured holes on the plot (if you use the `turbo` colour map)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# contour plot and gradient descent sequence here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Part 3 - support vector machines\n",
    "\n",
    "The [support vector machine (SVM)](https://en.wikipedia.org/wiki/Support-vector_machine) is a commonly-used machine learning model which uses an optimizer like the gradient descent algorithm you just implemented to help classify data.\n",
    "\n",
    "Suppose you have a collection of elements of $\\mathbb{R}^k$ called *data points*, each of which has a known *type* which is either 1 or -1.  This is called the *training data*.  You want to use these points to generate a *classifier* which, given a new data point, will tell you whether it is most likely to be of type 1 or of type -1.    For example, perhaps the points are derived from images of cats (type 1) and dogs (type -1), and you want to decide whether a new image is of a cat or of a dog.\n",
    "\n",
    "The simplest kind of SVM finds a *hyperplane* (a line in 2D space, a plane in 3D space, and so on) such that, as far as possible, all the type 1 training points are on one side of the hyperplane and all the type -1 training points are on the other side.  Given a new data point we then predict its type by simply checking which side of the hyperplane it lies on.\n",
    "\n",
    "Of course, in general it will not be possible to find any hyperplane that has all the type 1 points on one side and all the type -1 points on the other.  In that case the method finds the \"best\" hyperplane in a sense made precise by the loss function defined later."
   ]
  },
  {
   "attachments": {
    "dots_well_separated.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Write a function `generate_random_data(x0, y0, spread, n)` which generates `n` random two-dimensional data points centred at the point $(x_0, y_0)$.** The input `spread` to your function should control how widely spread out the points are around $(x_0, y_0)$: when `spread` is a small number, all data points should be close to $(x_0, y_0)$, and when `spread` is a large number, points should be more spread out.\n",
    "\n",
    "For the randomisation, you could use the `random` module or [`np.random.rand`](https://numpy.org/doc/stable/reference/random/generated/numpy.random.rand.html) or similar Numpy functions.\n",
    "\n",
    "It's up to you how these points are represented: choose whatever you think will be convenient later. You could store each point as a tuple `(x, y)` and return a list of `n` tuples, for example.  Alternatively you could return a list of lists `[x, y]`, or one-dimensional numpy arrays `np.array([x, y])`, or numpy column vectors `np.array([[x], [y]])`, or numpy row vectors `np.array([[x, y]])`, or you could return one big two-dimensional numpy array whose rows (or columns) are the data points.\n",
    "\n",
    "When you've done this, make two plots using `matplotlib.pyplot`. The first plot should show 20 random points generated with your `generate_random_data` function centred at (0, 1) as red dots, and 20 random points centred at (1, 0) as blue dots, with the `spread` parameter chosen so that the dots are tightly clustered.  The second plot should be the same as the first except with the `spread` parameter made larger so that there is some overlap between the two sets of dots.\n",
    "\n",
    "The first plot should look roughly like this:\n",
    "\n",
    "![dots_well_separated.png](attachment:dots_well_separated.png)"
   ]
  },
  {
   "attachments": {
    "dots_close_together.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "and the second should look roughly like this:\n",
    "\n",
    "![dots_close_together.png](attachment:dots_close_together.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def generate_random_data(x0, y0, spread, n):\n",
    "    # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# use this cell for your first plot, where the spread should be small\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# use this cell for your second plot, where the spread is larger\n"
   ]
  },
  {
   "attachments": {
    "dots_well_separated.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Part 4 - the SVM loss function\n",
    "\n",
    "Suppose we have *training data* consisting of $n$ vectors $\\mathbf{x}_1, \\ldots, \\mathbf{x}_n \\in \\mathbb{R}^k$ and that each $\\mathbf{x}_i$ has a *type* $y_i$ which is either 1 or -1.  In the following diagram I've coloured the type 1 points red and the type -1 points blue.\n",
    "\n",
    "![dots_well_separated.png](attachment:dots_well_separated.png)\n",
    "\n",
    "We call this data *linearly separable* if there exists a hyperplane such that all the type 1 points are on one side of the hyperplane and all the type -1 points are on the other side.  In the two-dimensional example above, the data is linearly separable: there are many possible straight lines which separate the red and blue dots.\n",
    "\n",
    "When the data is linearly separable we can choose a hyperplane with all the type 1 points above it and all the type -1 points below it. This hyperplane can be used as a classifier: if a new point is on the same side as the type 1 points we will classify the new point as type 1, and if it is on the other side we will classify it as having type -1.\n",
    "\n",
    "Mathematically, the classifier works like this.  Any hyperplane in $\\mathbb{R}^k$ can be written as the set of all points $\\mathbf{x}$ such that $\\mathbf{w}^T \\mathbf{x} = b$, for some vector $\\mathbf{w}$ and some scalar $b$.  The hyperplane divides $\\mathbb{R}^k$ into two pieces: points $\\mathbf{u}$ for which $\\mathbf{w}^T \\mathbf{u} > b$ (above the hyperplane) and points for which $\\mathbf{w}^T\\mathbf{u}  < b$ (below the hyperplane). Assume that the type 1 points $\\mathbf{x}_i$ satisfy $\\mathbf{w}^T \\mathbf{x}_i >b$. In that case, the classifier says that a new point $\\mathbf{u}$ has type 1 if $\\mathbf{w}^T \\mathbf{u} > b$, and that it has type -1 otherwise.\n",
    "\n",
    "As you can see from the diagram above, when data is linearly separable there may be many different hyperplanes which separate the two types of datapoint. The choice of hyperplane affects how the classifier performs, so we must choose it carefully.  One possibility is to use the separating hyperplane with the widest *margin*.  Consider the hyperplane $\\mathbf{w}^T \\mathbf{x} = b$.  There is another, parallel hyperplane $\\mathbf{w}^T \\mathbf{x} = b+1$ above it and another, parallel hyperplane $\\mathbf{w}^T \\mathbf{x} = b-1$ below it.  The area between these is called the margin, and we can then look for the hyperplane that maximises the width of the margin subject to all of the positive and negative datapoints being outside it."
   ]
  },
  {
   "attachments": {
    "margins.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT4AAADrCAAAAADV16XEAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAAmJLR0QA/4ePzL8AAAAJcEhZcwAADsMAAA7DAcdvqGQAAAAHdElNRQfoAR8UDwSYA45MAAAR00lEQVR42uVde1xVZbp+9gYUyLs5iFcUaOKyRUXwhng5dhkVHE09TaVHc2IjJqR51HRGmY6WOY3mnLhq02idGi+VYqYmlYoXYILNnTSVYRS8JgqCKMg+f1ghJrD2Ws+31mbz/LV/v73W+33vu95vre/yvO+rM0MmwjwWOsi9935czgtsx5CjCfSy71z2dUAVowdf/cdprY0gH/ay7+y/P9VZ695rDvneBwwDNu3UWgFtocR8ALyjQ65prYKW0Mn+dNzDnfdekj/+8frHQHlpv7bAihe0toQsKNAdANBmHpBqP0Tm3d29gfOl/TsCXbQ2hEyYlWN398hy+Xd/BBOhDxpB4bsPABCaV3NTay/QCEoHLwCgayxwqaaX1rpoAIb3AQCODvrrXa2VUR9Kv7z1OBn+xnA5992p6GSntRVkg2c+AKi9/YjWCqkL2uAFAOz33au1QuqC8un4GZOc5t2ZorVKaoI7eIFqe+4DsXJwBy/gaI/0ETlaa6Ua2OYDEDDniY+1VkstsAcvAOASXLTWSyUI8D7AxQUX5l7SWjU1IMR8ADp2M7SGnVQhgxcAkFs1VGvlxEOc+QDUxhgdtVZQLEQNXgBA5dEBX2utoFgI9T5g78W5WmsoFILNBwBHRum01lIYxJuverRTwq+1VlMUVPC+uzH5CVqrKQoqmA8AcPlXWmsqBEK/vPWoGz/nB61VFQGVzKc/1nGq1qqKgFqDF6h2RJ1KD0s9qKeQI/DU6jta60uGqv7wXnpQndYKc9H44I2vmc+37WkPrRXmonELjU8a8k96cx7AEi23oiMe48pr3HweX74SGiWAu/LM2qdv8aVKRNUNrrwmxqduVn6116d0DYZmGJ3oQrVCk6+3Lgkfrgg5z27Sfgqw84TWipN0afrv0aa1/stf5nNQ9NMmr1M7HOEv1wBT5QoACx9lyWx+2nxq3vVEf7ou19/+g9ob0e5nf/p1kvYBkbDqMH+wdMYaEa6S176vAKlNYvY+7gGghKmdblZWmd9+AbpkDPlLrQCxakLSzNhl6+aokBJ62/914jBfqLqQuLAYm+U/eCN9weWR1BfXy7U2gRJIXZc5RSdvC84X0IFdPp+pqO6c9WSB0kn4dVtclt7ic/sPe6VqHV4gHxbt911ccjz2SbpH1NqjztxC6c0Wbap037oxbMZldhfsgV1DM7U2hDxYuCc1scDbkMjfoJ6yYIKImZF4WL5Zn21sk+BF78fV9m21NoUcWL4j6nf8hVHLbrP78WhbfDu9VGtrWAwZG8r6sNyzvsn8rvh6Dfxca3NYCpknbXsWBK+nbVv8jEJn1RfBCiHzOCOkoIc3/xPi1Rc/rKTkl1ALck+DnNce2Dz2O35/zGd9WxIl0C5a7p2ucyperBzODoJxnuql66+tSSyBIpZBSWRu/DgBnar75JkWwkdQSNLY8/LoDV3pnbo6GQm+WlnEIih8yiE5nQdspXfq0ZSZ+zSyh4VQThHKDOsQTz58vodTQqRyofwdMzh1clC0AOpP1YSZ9N0JOgivaPuotLQh/HNb5+zuizQwiGUg8fv2zB/zDj+TTZ0et6ybkUCaIITkdDbwPyF63PVfVa2yRSwCj116zOgWw1+ylkSWH1TVIJaBSM6tiV0TsYKSULIBrnRT0x4Wgji7d4hKPRGQRu9hN2DqFtUY2BaCTA3fsWDynzvQO5lh7PaFdQZ2kdeW0wsdvXfQO+mfttI6rQddLfuIMCW8f0wfAT1dNyxYDYNYBruU4mHcTae+YSWzMJy/Y3L5pcKnre40WL8lkx0s4LA0LVkAq3xK/qA2KhlFOnRmFPXji90ROWN1ewHdTe7nLtwklkAP9ANe/ZAsdnpBtdcnArp7ZtibNWqYRTLMZrPZnD7wCTr55/Djk/7N5+QUzbkpnPdjAX6c99XuC6E/mOq1cSJY5cC/OnUS61LS8eMX0j4E2HaMK9ox+mhSYIaAPu/y2SbcLlJR74if9TRWkH27bkv3SLZMs9l83P9fQoekdNw3P/ttfnf2zEAQq3z4t31RZRWs8gfXvDnt2dOYQ+Ge8T35HY/ZlBgozCqS8eDqwBS4jvxYx5hEsMoxf8lvrYBS+Ysdl7OLN/ZmN5Jr1Cf40Ltezt/asRwPeyH+cIP8hq3b4hIpYr62I7RYgFQL8NCl/W4f8opBNyurzO9L/rMPHeJ/WIRPScdDjZrinU5/UHvdpl/iP/5TAuZFFuDhG0tBOQGoI6egn5DvbeB/QjzbIXeR5Jj3u/vPSr1UGhrZl7MDPg38ltuUc/TBf4wp4MoEANcynyMSL638DTmRQuPbms9EhRwgKzrg2AvBy+jnto++/3fNEmQ1bj7drLwx9NbCcksNfFb52MdRnqBJhpimNtW7tkX6M+SQUdetG+bOuMLX48ZHw7P5UptFM2cSfgZ6sMCkwv4+fFZ570PGM01fccjd3X0g1ru7u8/hNdvsOe9JZ/oiBFlGx4TH6VIB8/GRTTT6FlC7c4A34LeM2GTzuLyCvWK4m9BtVTV/FlbqMaO0yQtuYDW3RSkHivpi36+4bqIPy8oz8AMQXHM84uhCm4YkIx/8hu8qSX1mXuFLNZvNTUjVxPuA8WNw92PyzCCkoIcfnxII3PR7Tb0cWZIpQlem1iYayI1nGtvF83MSX1xo/0Fj/1W05W6oS2dYmTdVLmRrWhuzJmI5nztwy0mtPJ8WEtQK2YHQRfPPJ8gq79Y0agMj5qpCyrLoTXnT43cX2W/6pN4zr7Jlms3Zw6bxhf4S9d5XFgMAy5t2+qrXL2xhP8AbK3e+OYvuFnVnPOkyf4l68532BIA7zZGTzTpUsWuSHzf2iXEToFzYsyICFu9HvbP1yc7Ozs5ultqtw13/P5I3nUaYngwUEZgU+uJcwaRoOdzmC5Hl7J1AnI24kDCMrl3lV6F0mQ0gjxr+Az8IFTsiQwWwyoH3RwoMLZQ3PeoKhLxPHhfTCx29RaxCqkb+SRyfQ3ZggsnYZR97ZnXU2P9dfmDSucTXhU0B5cd13M3gc0xq1q9bslgEJfCf7vyARUBJXIddIPAG+ZDaYWn6V0PSBah5wIdNP/4Riibdu3rPuc2eyG93CSvnLw/Sn2ITT8xms9QNq8YwOX8ofcE/vRACWOUB+zvgMp9VTohpO+DOLoNwJNw9ln/CguidCSOVS2kAwr5O8fA15BVDcHbQwLfIHBEA0aueY2eQZ0RUFq95h70KxvfzyhKGsIWixgG11BA0VkDq2c6duZqKylW+PjmGSD9mbcom+ZDJN7pZ+dUDBCTDWTA6MJfYS9bSKy1yO33BcNjoGdeLLRTnevEWIbQjgaFpfVFFnhmMNvn78ymBvXXYPZ9UNYZ6ovI3/1Supk7RKbtH5XFlAkBwrQ+JvEidhH/cI5M9rxfEKk+5RhFDTgVRISCI9+KSY7FP8cXidFKk4kkM+Ti0PbB9UjFXZvet/xvOz1UO2O0LzFEqg3+aPGX4EKlUY6mYUCCCVd7v4ELFKxsRJT5P96AvQpBjtE/w5ncVt76eqOR2EVwGD2dkR1VwZQ44PlMAqxw4v3iKknWwICpI75uSgwUkQheWW+rLzwbmmTVQCXdRWH3eI678U/7PXw6MEZIQTHblUWFEpGBP3IgjbzpNKhDBKgfOB71aKe9OkTyuiu3DsrgSndcefG9MIb2jvXKv/I+8O4UW1zZv6UI/5a/bvPz3f+LX9qjT47YMqUJZhLrZoTCncGXqw3LOGMhMdQB63PCMlTG15C8nG6LUc1oJW2ZSXxGs8vyglyy+RziH1TXHaxNbZki+iHIX3kdWW3yP0HdfPS6zYx5NRucEPqscNRMWW7Q7Ib/ghCWoMFweyU0K6zqnYk7lCDqfw84l4qQlqziVvO/SIjs6e6okMi9+LL2nVblDLbhaJfMB1Y78YAEx5S6Alf8pNW2KamVFHFEzOJEdmCSk3AXgOvaPEq9UzfsA5Bp70rPqZoa5CGCVX9j7e2kXqmk+1BXxU2cKCkwC9gyTsDuhak0gvTvwInnTyT4qNTWAfMAHAEgzSKEf82fvTWOv2+w6tsyk3mEC2HumubXNXqN6RaoJedPoTOOQHBGs8oGb7XCquWKc/KcmAYkFbIkpPhNFZJSM+vU3Tf6vTT202tGryMECQaZRgwVQAt9565UmMzyp+uWtR8mmVfQhfCbikoCEkmYdbj7SaF81Mh8ApLmza6zuWDD5bQE0h8VZcY2d22hYzDDZsJUemASvnfyOrp048kIjf2nofchY+Q+6r6QY3QWUu7jeqZE/tCyl6b+3PS6RWeWjsoMG8T8hnYANYWUP+UPrSqRxA8lnIQ5L05ID+OUuMLeNz8PKEQuYLFmET9zOs0UKylWe+ZBFiJbvvnuotUcNuzzZtde+2DhVQF+TMxY17KrWgxewBzY+dUa5nPvRJeHDFSHsEBgA7of8G2YP1d58AF4ZP4xNYB5t8vffSP+E9Nu3ouHutvaDFwBQ0oMfsXxq3vVEfwF9PZc27effVuF9QE8dPp13nSvzseSoSVGScxJLR1l0Pf3YSswHYBxYwQI/QVC5iwGmEed+bsI6Bi8A4IR3R7rMb8IfE1HuAnfyBwHW5H3A8I44+TZ5I2tslpByFzg5IbIc1mU+AG2/DCDnD3aKTt4WnE/vqCG/8iNY1+AFAPyfrx9bpPmDJbOjHUV09pqVeR/wvB+qkrgidbOySn0FlLtA8TSr8z4A30/2fJedymDvfBGs8rtW530APLPocUmYWODty6cE2lmj993DKXbmrmxjmwR27lBr9D4AwLngheQVg9/xF0Yta+7c1kJYrfl655W9QRapD8s968std2G9gxeo0+OWE1nmngXB64kHfFbrfQD0uPHYu/xc5UxWuTV7H4DC8McT2DJNRud4VrkLKzcfzNf47NvamDURr3ECk6x58AKArivujPuCK9M+ypRLKndh7d4HAAfnPRnLlklilVu79wHAE7lz6TJJrPKW4H0AgOXP+ZIlZoZ1iFe6smkJ3gcA5j7j/kAWOTh1cpDSXOUtxvtwcf9susyiiBJl5S5ajvkAYNcIdmjhnvlj3lGQk7ilDN57yDBsJj/ukJzOBgWfkJblfciOi6U/8GNGtxi5qQdbmPkA4Ds38rlFTeyaiBXyWEota/ACAOL9yAXyHKJSTwSkybtXBGdPMJIG89l7211kBSa1QO9DSEY7VAgodyEj3LMFvvsAAK+aFK8YHkRKeH+LWeXNeZ85Ly8vL4+f7F0p1k0edUG5lAYYlWU5q7w576tsBwDFfK6/YpQLqMxzet7VxABLbmgue2ebaADopJJJLEEH4O3CP3OrmHgc3BE6Y7UlwSZaf0aVoHyB63dsmdfCeu6UfnVL/XT8iGwDf+pwxOghudxFS5y43Ac/PQ68Qf6wBZv8h0hllbcs73vuEoC3GhaiKJ5fvI2dFPb7cImscmr1CuHIPw/ggaSyfT/fSadOeSZ/MElSuYuW5X2NovjEs2SJl/77WMzTzV5lI+bLfb5XrBtZ5qFwz2ZZ5S380/ETDBnB7EUIxmT6BDd3FGIj3gcAuJ3Lrm50o7lICRvxPgDAqdCXy7kSm40zsSXzGfLvbFO5SVsavPdwlZ2foynYkvcBAIq8Nogrx/sL2Jz5+h3f+7p6rdne4IW52omf57MR2Jz3ATonXPPdrU5bNmg+AF1ily5VpSEbHLwAgNsX3NRoxja9D2jrhtvPm4Q3Y6vmA9Bm/G+iRbdhq4MXAHAl6wnBLdi0+QDgr9NdBUq34cELAKi77BcnULytm0+/+htyxbgGsPnBCwBI8efXLQRg+953D1sNB8QIbh3eh/1xnwlxlFZiPgC40J2fZqx1DF4AwLLgAuVCHkArMt/7vwu9xZbZigYvUOOAWi6tohV5H+AALJp1hSmxVZkPwJu/MjDt16oGLwDg30yisarmK0kE0Ha5ii0+HDFXl5FqrKpqvvShANqJXINKw/kFhfvdKJJUNV91EQA7djyGHBwYx8m03frefT/haNFM5UJa25e3Ho9sGF+sWEjrNd+g9EnKp9Ctd/ACAC6eDlJ0f+v1PgBA0bPGMiX3t3LzDc93yFRyfysfvACA2vNucm9t5d4HADDJT1P5/x7RIbewtIxBAAAAJXRFWHRkYXRlOmNyZWF0ZQAyMDI0LTAxLTMxVDIwOjE1OjA0KzAwOjAwSKtLhQAAACV0RVh0ZGF0ZTptb2RpZnkAMjAyNC0wMS0zMVQyMDoxNTowNCswMDowMDn28zkAAAAZdEVYdFNvZnR3YXJlAHd3dy5pbmtzY2FwZS5vcmeb7jwaAAAAAElFTkSuQmCC"
    }
   },
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![margins.png](attachment:margins.png)"
   ]
  },
  {
   "attachments": {
    "margins.svg": {
     "image/svg": "\u0000"
    }
   },
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The image above shows type 1 data points as + signs and type -1 data points as - signs.  The solid line in the centre is a hyperplane $\\mathbf{w}^T \\mathbf{x} = b$, and the parallel dotted lines either side of it are the boundaries of the margin, whose equations are $\\mathbf{w}^T \\mathbf{x} = b \\pm 1$. The area between the two dotted lines is the margin and its width is the distance from one dotted line to the other.\n",
    "\n",
    "For a vector $\\mathbf{u} = \\begin{pmatrix} u_1 \\\\ \\vdots \\\\ u_k \\end{pmatrix}$ we define $||\\mathbf{u}||$, the length of $\\mathbf{u}$, to be $\\sqrt{\\sum_{i=1}^k u_i^2}$.  It turns out that the width of the margin is equal to $2/||\\mathbf{w}||$, so maximising the width of the margin is equivalent to minimising $||\\mathbf{w}||$ subject to the constraint that all type 1 data points $\\mathbf{x}_+$ satisfy $\\mathbf{w}^T \\mathbf{x}_+ \\geqslant b+1$ (that is, they are above the margin) and all type -1 datapoints $\\mathbf{x}_-$ satisfy $\\mathbf{w}^T \\mathbf{x}_- \\leqslant b - 1$ (that is, they are below the margin).\n",
    "\n",
    "In general the data we work with may not be linearly separable. Consider the example below where as before, type 1 datapoints are red and type -1 datapoints are blue."
   ]
  },
  {
   "attachments": {
    "dots_close_together.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![dots_close_together.png](attachment:dots_close_together.png)\n",
    "\n",
    "There is no straight line which separates the red and blue dots.  To help us make a classifier, recall that a vector $\\mathbf{u}$ lies above the margin if $\\mathbf{w}^T \\mathbf{u} \\geqslant b + 1$ and below it if $\\mathbf{w}^T \\mathbf{u} \\leqslant b - 1$.  A type 1 point $\\mathbf{x}_i$ is above the margin if $\\mathbf{w}^T\\mathbf{x}_i \\geqslant b+1$, that is, $\\mathbf{w}^T\\mathbf{x}_i - b \\geqslant 1$ and a type -1 point $\\mathbf{x}_i$ is below the margin if $\\mathbf{w}^T \\mathbf{x}_i \\leqslant b - 1$, that is $\\mathbf{w}^T\\mathbf{x}_i -b\\geqslant 1$.  Letting $y_i=1$ if $\\mathbf{x}_i$ is type 1 and $y_i=-1$ if $\\mathbf{x}_i$ is type -1, we can summarise this by saying all data points $\\mathbf{x}_i$ are on the correct side of the margin if and only if all of the inequalities\n",
    "\n",
    "$$ y_i(\\mathbf{w}^T \\mathbf{x}_i -b) \\geq 1$$\n",
    "\n",
    "are true, or equivalently, if $1-y_i(\\mathbf{w}^T \\mathbf{x}_i - b) \\leq 0$ for all $i$. Thus the sum\n",
    "\n",
    "$$ \\sum_{i=1}^n \\max(0, 1-y_i(\\mathbf{w}^T \\mathbf{x}_i - b)) $$\n",
    "\n",
    "is a nonnegative quantity that is zero if all data points are on the correct sides of the margins $\\mathbf{w}^T \\mathbf{x}  =b \\pm 1$ and which gets bigger as points get further away from the correct side of the margin.  This is called the [hinge loss](https://en.wikipedia.org/wiki/Hinge_loss)\n",
    "\n",
    "The SVM classifier then needs to make a tradeoff between making $||\\mathbf{w}||$ small and making $$ \\sum_{i=1}^n \\max(0, 1-y_i(\\mathbf{w}^T \\mathbf{x}_i - b)) $$ small so that points are close to being on the right side of the margins.  It does this by choosing a constant $\\lambda$ and minimizing the **loss function**\n",
    "\n",
    "$$\\lambda ||\\mathbf{w}||^2 + \\frac{1}{n}\\sum_{i=1}^n \\max(0, 1-y_i(\\mathbf{w}^T \\mathbf{x}_i - b)).$$\n",
    "\n",
    "The parameter $\\lambda$ determines the tradeoff between margin size and classification error.  If we don't mind having a small margin but hate having points on the wrong side of the margin we make $\\lambda$ small; if we absolutely must have a big margin but don't care about a few mis-classified training points we make $\\lambda$ big. You can read more details about this loss function and some applications of the SVM on [Andrew Zisserman](https://www.robots.ox.ac.uk/~az/lectures/ml/index.html)'s [lecture slides](https://www.robots.ox.ac.uk/~az/lectures/ml/lect2.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Write a function `loss(bw, data)` which computes the loss function above.**  You can set $\\lambda = 0.01$ to begin with.  The input `bw` should be a 1-dimensional Numpy array whose first element represents $b$ in the formula above and whose remaining elements are the entries of the vector $\\mathbf{w}$.  The input `data` should somehow contain all the vectors $\\mathbf{x}_i$ and their types $y_i$, but it's up to you exactly what kind of Python object to use.  However, you can't change the inputs of the `loss` function: it must take these two arguments only (because we're going to use it with the `scipy.optimize.minimize` function later which requires the function to be of this form)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Part 5 - finding and plotting the minimizing hyperplane\n",
    "\n",
    "To find a choice of $b$ and $\\mathbf{w}$ which (approximately) minimizes the loss function defined in the last part you are going to use the [`scipy.optimize.minimize`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html) function.  **Read the documentation** by [clicking here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html) to find out about it.  Your call to `minimize` should only supply the fun, x0, and args parameters: don't change any of the other stuff.\n",
    "\n",
    "In this part you are going to practise using `minimize` on a simple example function which I have defined in the cell below.  The function `f(bw, data)` expects a one-dimensional numpy array `bw` of shape `(2,)` and a second argument `data`, again a one-dimensional array of shape `(2,)`.  \n",
    "\n",
    "**Use `scipy.optimize.minimize` to find the minimum value of `f` and the point at which that minimum occurs**.\n",
    "\n",
    "Of course, the minimum value of `f` is 2 and this is attained at the point specified by `testdata`, so you will be able to see if your `minimize` call has worked correctly.  `minimize` returns a Python object with several instance variables, most of which you can ignore: the important ones are called `fun`, which tells you the minimum value, and `x`, which tells you the point at which the minimum occurred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def f(bw, data):\n",
    "    return 2 + (bw[0] - data[0]) ** 2 + (bw[1] - data[1]) ** 2\n",
    "\n",
    "testdata = np.array([1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# use minimize here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now that you've learned to use `scipy.optimize.minimize`, you're ready to\n",
    "**write a function `svm_demo(n, redCentre, blueCentre, spread)`** which does the following.\n",
    "\n",
    " - calls your `generate_random_data` to generate `n` random data points centred at `redCentre` and `n` random data points centred at `blueCentre` using `spread` to control how spread out they are\n",
    " - uses `minimize` to find the hyperplane $\\mathbf{w}^T \\mathbf{x} = b$ that minimizes the SVM loss function\n",
    " - plots the type 1 points (in red), the type -1 points (in blue), the minimizing hyperplane, and the two margin hyperplanes $\\mathbf{w}^T \\mathbf{x} = b \\pm 1$ all on the same axes.  Don't worry if the points aren't all outside the margins.\n",
    "\n",
    "**Call the function `svm_demo(20, [0, 1], [1, 0], s)` where `s` is just big enough so that the points aren't linearly separable.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def svm_demo(n, redCentre, blueCentre, spread):\n",
    "    # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# call your svm_demo function here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Submitting your project\n",
    "\n",
    "**Make sure you have done all of the following things.**\n",
    "\n",
    "0. Included **all** group members' student numbers at the top of this notebook.\n",
    "1. Read through every part of the project to check you have answered all of it.\n",
    "2. Carefully read and followed all of the [MATH0011 project instructions](https://www.ucl.ac.uk/~ucahmto/0011/project-instructions.html).\n",
    "3. Checked that all of your code works correctly.\n",
    "\n",
    "If you have, you're ready to submit.  **One** of the group members should download the completed notebook (in CoCalc, click the File menu next to the green Save button, then click Download) and submit it on the MATH0011 Moodle.  Please submit **one .ipynb file per group.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "/usr/bin/python3",
    "-m",
    "ipykernel",
    "--HistoryManager.enabled=False",
    "--matplotlib=inline",
    "-c",
    "%config InlineBackend.figure_formats = set(['retina'])\nimport matplotlib; matplotlib.rcParams['figure.figsize'] = (12, 7)",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3 (system-wide)",
   "env": {
   },
   "language": "python",
   "metadata": {
    "cocalc": {
     "description": "Python 3 programming language",
     "priority": 100,
     "url": "https://www.python.org/"
    }
   },
   "name": "python3",
   "resource_dir": "/ext/jupyter/kernels/python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}